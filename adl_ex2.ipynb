{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 37\n",
    "def get_data_set(batch_size):\n",
    "    #\n",
    "    # CenterCrop is one possibility, but you can also try to resize the image\n",
    "    #\n",
    "    transform = torchvision.transforms.Compose(\n",
    "            [torchvision.transforms.ToTensor(),\n",
    "             torchvision.transforms.CenterCrop(256)])\n",
    "    data_train = torchvision.datasets.OxfordIIITPet(root='data/OxfordIIITPet', download=True, transform=transform)\n",
    "    data_test = torchvision.datasets.OxfordIIITPet(root='data/OxfordIIITPet', split='test', download=True,\n",
    "                                                   transform=transform)\n",
    "    len_train = (int)(0.8 * len(data_train))\n",
    "    len_val = len(data_train) - len_train\n",
    "    data_train_subset, data_val_subset = torch.utils.data.random_split(\n",
    "            data_train, [len_train, len_val])\n",
    "\n",
    "    data_train_loader = torch.utils.data.DataLoader(dataset=data_train_subset, shuffle=True, batch_size=batch_size)\n",
    "    data_val_loader = torch.utils.data.DataLoader(dataset=data_val_subset, shuffle=True, batch_size=batch_size)\n",
    "    data_test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)\n",
    "\n",
    "    print(f'Length of Datasets: train-{len_train}, val- {len_val}, test-{len(data_train)}')\n",
    "\n",
    "    return data_train_loader, data_val_loader, data_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        # to complete\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # to complete\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    metrics = MulticlassAccuracy(num_classes=37)\n",
    "    total_step = len(train_loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        metrics.reset()\n",
    "\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            metrics.update(predicted, labels)\n",
    "            train_acc = metrics.compute()\n",
    "\n",
    "            if (step+1) % 10 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                       f'Step [{step+1}/{total_step}], '\n",
    "                       f'Loss: {loss.item(): .4f}, '\n",
    "                       f'Accuracy: {train_acc: .2f}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metrics.reset()\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                metrics.update(predicted, labels)\n",
    "            val_acc = metrics.compute()\n",
    "\n",
    "            print(f'Val Accuracy: {val_acc: .2f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        # test if it worked\n",
    "        x = torch.ones(1, device=device)\n",
    "        print('Using CUDA device')\n",
    "\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        x = torch.ones(1, device=device)\n",
    "        print('Using MPS device')\n",
    "    else:\n",
    "        print('Using CPU')\n",
    "        device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = 64\n",
    "    train_loader, val_loader, test_loader = get_data_set(batch_size)\n",
    "    # to complete\n",
    "    device = get_device()\n",
    "    cnn = DeepCNN()\n",
    "    n_parameters = sum(p.numel() for p in cnn.parameters())\n",
    "    print(f'Number of Parameters: {n_parameters}')\n",
    "\n",
    "    n_epochs = 20\n",
    "    lr = 0.01\n",
    "    weight_decay = 0.001\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    final_model, results = train(cnn, train_loader, val_loader, loss_func, optimizer, n_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Datasets: train-2944, val- 736, test-3680\n",
      "Using CPU\n",
      "Number of Parameters: 9968933\n",
      "Epoch [1/20], Step [10/46], Loss:  54.8296, Accuracy:  0.02\n",
      "Epoch [1/20], Step [20/46], Loss:  6.5032, Accuracy:  0.02\n",
      "Epoch [1/20], Step [30/46], Loss:  3.7061, Accuracy:  0.02\n",
      "Epoch [1/20], Step [40/46], Loss:  3.6599, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [2/20], Step [10/46], Loss:  3.6154, Accuracy:  0.03\n",
      "Epoch [2/20], Step [20/46], Loss:  3.6047, Accuracy:  0.03\n",
      "Epoch [2/20], Step [30/46], Loss:  3.5841, Accuracy:  0.03\n",
      "Epoch [2/20], Step [40/46], Loss:  3.6075, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [3/20], Step [10/46], Loss:  3.6141, Accuracy:  0.03\n",
      "Epoch [3/20], Step [20/46], Loss:  3.6492, Accuracy:  0.03\n",
      "Epoch [3/20], Step [30/46], Loss:  3.6075, Accuracy:  0.03\n",
      "Epoch [3/20], Step [40/46], Loss:  3.8781, Accuracy:  0.03\n",
      "Val Accuracy:  0.04\n",
      "Epoch [4/20], Step [10/46], Loss:  3.5864, Accuracy:  0.02\n",
      "Epoch [4/20], Step [20/46], Loss:  3.5741, Accuracy:  0.03\n",
      "Epoch [4/20], Step [30/46], Loss:  3.5904, Accuracy:  0.03\n",
      "Epoch [4/20], Step [40/46], Loss:  3.6163, Accuracy:  0.03\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Exercise 02 for advanced deep learning course\n",
    "#\n",
    "#\n",
    "# Construct a deep CNN model for Pet Classification\n",
    "#\n",
    "#\n",
    "# This version does not use wandb, but tensorboard or wandb are recommended\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ad_DeLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
