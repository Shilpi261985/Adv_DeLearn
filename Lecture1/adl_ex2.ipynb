{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 37\n",
    "def get_data_set(batch_size):\n",
    "    #\n",
    "    # CenterCrop is one possibility, but you can also try to resize the image\n",
    "    #\n",
    "    transform = torchvision.transforms.Compose(\n",
    "            [torchvision.transforms.ToTensor(),\n",
    "             torchvision.transforms.CenterCrop(256)])\n",
    "    data_train = torchvision.datasets.OxfordIIITPet(root='data/OxfordIIITPet', download=True, transform=transform)\n",
    "    data_test = torchvision.datasets.OxfordIIITPet(root='data/OxfordIIITPet', split='test', download=True,\n",
    "                                                   transform=transform)\n",
    "    len_train = (int)(0.8 * len(data_train))\n",
    "    len_val = len(data_train) - len_train\n",
    "    data_train_subset, data_val_subset = torch.utils.data.random_split(\n",
    "            data_train, [len_train, len_val])\n",
    "\n",
    "    data_train_loader = torch.utils.data.DataLoader(dataset=data_train_subset, shuffle=True, batch_size=batch_size)\n",
    "    data_val_loader = torch.utils.data.DataLoader(dataset=data_val_subset, shuffle=True, batch_size=batch_size)\n",
    "    data_test_loader = torch.utils.data.DataLoader(data_test, batch_size=batch_size)\n",
    "\n",
    "    print(f'Length of Datasets: train-{len_train}, val- {len_val}, test-{len(data_train)}')\n",
    "\n",
    "    return data_train_loader, data_val_loader, data_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        # to complete\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # to complete\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    run = wandb.init(project=\"DeepCNN_PetClassification\", config={'epochs': num_epochs, \n",
    "                                                       'batch_size': train_loader.batch_size}\n",
    "                                                       )\n",
    "    metrics = MulticlassAccuracy(num_classes=37)\n",
    "    total_step = len(train_loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        metrics.reset()\n",
    "\n",
    "        for step, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            metrics.update(predicted, labels)\n",
    "            train_acc = metrics.compute()\n",
    "\n",
    "            train_metrics = \\\n",
    "                {'train/train_loss:': loss.item(),\n",
    "                 'train/train_acc'        : train_acc,\n",
    "                 'train/epoch'            : epoch+1}\n",
    "\n",
    "            if (step+1) % 10 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                       f'Step [{step+1}/{total_step}], '\n",
    "                       f'Loss: {loss.item(): .4f}, '\n",
    "                       f'Accuracy: {train_acc: .2f}')\n",
    "                #log loss and accuracy to wandb\n",
    "                wandb.log(train_metrics)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metrics.reset()\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                metrics.update(predicted, labels)\n",
    "            val_acc = metrics.compute()\n",
    "            val_metrics = {'val/val_loss' : val_loss_mean,\n",
    "                           'val/val_acc'       : val_acc}\n",
    "\n",
    "            print(f'Val Accuracy: {val_acc: .2f}')\n",
    "            #log Validation accuracy to wandb\n",
    "            wandb.log(val_metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        # test if it worked\n",
    "        x = torch.ones(1, device=device)\n",
    "        print('Using CUDA device')\n",
    "\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        x = torch.ones(1, device=device)\n",
    "        print('Using MPS device')\n",
    "    else:\n",
    "        print('Using CPU')\n",
    "        device = torch.device('cpu')\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    batch_size = 64\n",
    "    train_loader, val_loader, test_loader = get_data_set(batch_size)\n",
    "    # to complete\n",
    "    device = get_device()\n",
    "    cnn = DeepCNN()\n",
    "    n_parameters = sum(p.numel() for p in cnn.parameters())\n",
    "    print(f'Number of Parameters: {n_parameters}')\n",
    "\n",
    "    n_epochs = 20\n",
    "    lr = 0.01\n",
    "    weight_decay = 0.001\n",
    "    optimizer = optim.Adam(cnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    final_model, results = train(cnn, train_loader, val_loader, loss_func, optimizer, n_epochs, device)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Datasets: train-2944, val- 736, test-3680\n",
      "Using CPU\n",
      "Number of Parameters: 9968933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mitsshilpi26\u001b[0m (\u001b[33mg27\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Shilpi\\BFH\\MSE_Courses\\Semester 2\\TSM_AdvDeLearn\\Lecture1_DL_Recap\\wandb\\run-20241024_141852-pgiyma9m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g27/DeepCNN_PetClassification/runs/pgiyma9m' target=\"_blank\">peachy-glade-1</a></strong> to <a href='https://wandb.ai/g27/DeepCNN_PetClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g27/DeepCNN_PetClassification' target=\"_blank\">https://wandb.ai/g27/DeepCNN_PetClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g27/DeepCNN_PetClassification/runs/pgiyma9m' target=\"_blank\">https://wandb.ai/g27/DeepCNN_PetClassification/runs/pgiyma9m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [10/46], Loss:  67.1935, Accuracy:  0.04\n",
      "Epoch [1/20], Step [20/46], Loss:  5.0284, Accuracy:  0.03\n",
      "Epoch [1/20], Step [30/46], Loss:  3.6077, Accuracy:  0.02\n",
      "Epoch [1/20], Step [40/46], Loss:  3.5962, Accuracy:  0.02\n",
      "Val Accuracy:  0.02\n",
      "Epoch [2/20], Step [10/46], Loss:  3.6333, Accuracy:  0.04\n",
      "Epoch [2/20], Step [20/46], Loss:  3.7119, Accuracy:  0.03\n",
      "Epoch [2/20], Step [30/46], Loss:  3.6081, Accuracy:  0.03\n",
      "Epoch [2/20], Step [40/46], Loss:  3.6010, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [3/20], Step [10/46], Loss:  3.5878, Accuracy:  0.03\n",
      "Epoch [3/20], Step [20/46], Loss:  3.6080, Accuracy:  0.04\n",
      "Epoch [3/20], Step [30/46], Loss:  3.6574, Accuracy:  0.03\n",
      "Epoch [3/20], Step [40/46], Loss:  3.6104, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [4/20], Step [10/46], Loss:  3.6079, Accuracy:  0.04\n",
      "Epoch [4/20], Step [20/46], Loss:  3.7976, Accuracy:  0.03\n",
      "Epoch [4/20], Step [30/46], Loss:  3.7118, Accuracy:  0.03\n",
      "Epoch [4/20], Step [40/46], Loss:  4.4953, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [5/20], Step [10/46], Loss:  4.1788, Accuracy:  0.04\n",
      "Epoch [5/20], Step [20/46], Loss:  3.5808, Accuracy:  0.03\n",
      "Epoch [5/20], Step [30/46], Loss:  3.6207, Accuracy:  0.03\n",
      "Epoch [5/20], Step [40/46], Loss:  3.6226, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [6/20], Step [10/46], Loss:  3.6066, Accuracy:  0.03\n",
      "Epoch [6/20], Step [20/46], Loss:  3.6016, Accuracy:  0.04\n",
      "Epoch [6/20], Step [30/46], Loss:  3.6279, Accuracy:  0.04\n",
      "Epoch [6/20], Step [40/46], Loss:  3.6050, Accuracy:  0.03\n",
      "Val Accuracy:  0.03\n",
      "Epoch [7/20], Step [10/46], Loss:  3.5486, Accuracy:  0.03\n",
      "Epoch [7/20], Step [20/46], Loss:  3.6299, Accuracy:  0.03\n",
      "Epoch [7/20], Step [30/46], Loss:  3.6131, Accuracy:  0.03\n",
      "Epoch [7/20], Step [40/46], Loss:  4.1724, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [8/20], Step [10/46], Loss:  3.9007, Accuracy:  0.03\n",
      "Epoch [8/20], Step [20/46], Loss:  3.6169, Accuracy:  0.03\n",
      "Epoch [8/20], Step [30/46], Loss:  3.6081, Accuracy:  0.03\n",
      "Epoch [8/20], Step [40/46], Loss:  3.6116, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [9/20], Step [10/46], Loss:  3.6068, Accuracy:  0.03\n",
      "Epoch [9/20], Step [20/46], Loss:  3.6181, Accuracy:  0.03\n",
      "Epoch [9/20], Step [30/46], Loss:  3.5971, Accuracy:  0.03\n",
      "Epoch [9/20], Step [40/46], Loss:  3.6166, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [10/20], Step [10/46], Loss:  3.6153, Accuracy:  0.03\n",
      "Epoch [10/20], Step [20/46], Loss:  4.3145, Accuracy:  0.02\n",
      "Epoch [10/20], Step [30/46], Loss:  3.6070, Accuracy:  0.03\n",
      "Epoch [10/20], Step [40/46], Loss:  3.6244, Accuracy:  0.03\n",
      "Val Accuracy:  0.01\n",
      "Epoch [11/20], Step [10/46], Loss:  3.6715, Accuracy:  0.03\n",
      "Epoch [11/20], Step [20/46], Loss:  3.6010, Accuracy:  0.03\n",
      "Epoch [11/20], Step [30/46], Loss:  3.6183, Accuracy:  0.03\n",
      "Epoch [11/20], Step [40/46], Loss:  3.6000, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [12/20], Step [10/46], Loss:  3.6129, Accuracy:  0.03\n",
      "Epoch [12/20], Step [20/46], Loss:  3.6158, Accuracy:  0.03\n",
      "Epoch [12/20], Step [30/46], Loss:  3.6232, Accuracy:  0.03\n",
      "Epoch [12/20], Step [40/46], Loss:  3.6117, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [13/20], Step [10/46], Loss:  3.6093, Accuracy:  0.04\n",
      "Epoch [13/20], Step [20/46], Loss:  3.6076, Accuracy:  0.03\n",
      "Epoch [13/20], Step [30/46], Loss:  3.6162, Accuracy:  0.03\n",
      "Epoch [13/20], Step [40/46], Loss:  3.6134, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [14/20], Step [10/46], Loss:  3.6032, Accuracy:  0.03\n",
      "Epoch [14/20], Step [20/46], Loss:  3.6101, Accuracy:  0.03\n",
      "Epoch [14/20], Step [30/46], Loss:  3.6158, Accuracy:  0.03\n",
      "Epoch [14/20], Step [40/46], Loss:  3.6273, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [15/20], Step [10/46], Loss:  3.6052, Accuracy:  0.03\n",
      "Epoch [15/20], Step [20/46], Loss:  3.6143, Accuracy:  0.02\n",
      "Epoch [15/20], Step [30/46], Loss:  3.6067, Accuracy:  0.02\n",
      "Epoch [15/20], Step [40/46], Loss:  3.6138, Accuracy:  0.02\n",
      "Val Accuracy:  0.02\n",
      "Epoch [16/20], Step [10/46], Loss:  3.6210, Accuracy:  0.04\n",
      "Epoch [16/20], Step [20/46], Loss:  3.6090, Accuracy:  0.03\n",
      "Epoch [16/20], Step [30/46], Loss:  3.6113, Accuracy:  0.03\n",
      "Epoch [16/20], Step [40/46], Loss:  4.0393, Accuracy:  0.03\n",
      "Val Accuracy:  0.01\n",
      "Epoch [17/20], Step [10/46], Loss:  3.6073, Accuracy:  0.03\n",
      "Epoch [17/20], Step [20/46], Loss:  3.6211, Accuracy:  0.03\n",
      "Epoch [17/20], Step [30/46], Loss:  3.6147, Accuracy:  0.03\n",
      "Epoch [17/20], Step [40/46], Loss:  4.0278, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [18/20], Step [10/46], Loss:  3.6132, Accuracy:  0.03\n",
      "Epoch [18/20], Step [20/46], Loss:  3.6313, Accuracy:  0.02\n",
      "Epoch [18/20], Step [30/46], Loss:  3.6200, Accuracy:  0.02\n",
      "Epoch [18/20], Step [40/46], Loss:  3.9816, Accuracy:  0.02\n",
      "Val Accuracy:  0.02\n",
      "Epoch [19/20], Step [10/46], Loss:  3.6090, Accuracy:  0.03\n",
      "Epoch [19/20], Step [20/46], Loss:  3.6222, Accuracy:  0.02\n",
      "Epoch [19/20], Step [30/46], Loss:  3.6231, Accuracy:  0.03\n",
      "Epoch [19/20], Step [40/46], Loss:  3.6348, Accuracy:  0.03\n",
      "Val Accuracy:  0.02\n",
      "Epoch [20/20], Step [10/46], Loss:  3.6104, Accuracy:  0.03\n",
      "Epoch [20/20], Step [20/46], Loss:  3.6583, Accuracy:  0.03\n",
      "Epoch [20/20], Step [30/46], Loss:  3.6153, Accuracy:  0.03\n",
      "Epoch [20/20], Step [40/46], Loss:  3.6794, Accuracy:  0.02\n",
      "Val Accuracy:  0.01\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable DeepCNN object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Exercise 02 for advanced deep learning course\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# This version does not use wandb, but tensorboard or wandb are recommended\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(cnn\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[0;32m     14\u001b[0m loss_func \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 16\u001b[0m final_model, results \u001b[38;5;241m=\u001b[39m train(cnn, train_loader, val_loader, loss_func, optimizer, n_epochs, device)\n\u001b[0;32m     17\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable DeepCNN object"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Exercise 02 for advanced deep learning course\n",
    "#\n",
    "#\n",
    "# Construct a deep CNN model for Pet Classification\n",
    "#\n",
    "#\n",
    "# This version does not use wandb, but tensorboard or wandb are recommended\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ad_DeLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
